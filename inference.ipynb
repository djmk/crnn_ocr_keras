{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPool2D, CuDNNLSTM, CuDNNGRU, Bidirectional, TimeDistributed, Reshape, Lambda\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras.backend import ctc_decode, get_session, ctc_batch_cost\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import Sequence, multi_gpu_model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import groupby\n",
    "from glob import iglob\n",
    "import editdistance\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Found 102000 images <=\n",
      "=> Max width of images 1928 <=\n",
      "=> Vocab size of dataset 68 <=\n",
      "=> Max string len 80 <=\n"
     ]
    }
   ],
   "source": [
    "ngpus = 4\n",
    "\n",
    "image_list = list(iglob('../dataset/*/*'))\n",
    "image_list.sort()\n",
    "print(f'=> Found {len(image_list)} images <=')\n",
    "\n",
    "max_w = 1928\n",
    "max_h = 64\n",
    "print(f'=> Max width of images {max_w} <=')\n",
    "\n",
    "labels = ' '.join([x.split('/')[-1].split('_')[0] for x in image_list])\n",
    "vocab = sorted(list(set(labels)))\n",
    "vocab_size = len(vocab)\n",
    "print(f'=> Vocab size of dataset {vocab_size} <=')\n",
    "\n",
    "letter_idx = {x: idx for idx, x in enumerate(vocab)}\n",
    "idx_letter = {v: k for k, v in letter_idx.items()}\n",
    "idx_letter[len(idx_letter)] = ''\n",
    "\n",
    "string_lens = [len(x) for x in [x.split('/')[-1].split('_')[0] for x in image_list]]\n",
    "max_string_len = max(string_lens)\n",
    "print(f'=> Max string len {max_string_len} <=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model <=\n",
      "WARNING:tensorflow:From /home/mia/tf-trt/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mia/tf-trt/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/mia/tf-trt/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:5077: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/mia/tf-trt/lib/python3.6/site-packages/tensorflow/python/keras/backend.py:5056: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "=> Build completed successfully <=\n",
      "=> Creating model replicas for distributed training across 4 gpus <=\n"
     ]
    }
   ],
   "source": [
    "h, w = max_w, max_h\n",
    "\n",
    "def ctc_loss(tensor_list):\n",
    "    y_pred, y_true, input_length, label_length = tensor_list\n",
    "    y_pred = y_pred[:,2:,:]\n",
    "    return ctc_batch_cost(y_true, y_pred,input_length,label_length)\n",
    "\n",
    "def dummy_loss(y_true, y_pred):\n",
    "    return y_pred\n",
    "\n",
    "downscale_factor = 4\n",
    "print('=> Building model <=')\n",
    "base_model = ResNet50(weights=None, include_top=False, input_shape=(h,w,1))\n",
    "conv_features = base_model.get_layer('activation_9').output\n",
    "conv_features = Conv2D(filters=128, kernel_size=3, padding='same', kernel_initializer='he_normal')(conv_features)\n",
    "y = Reshape(target_shape=(h // downscale_factor, w // downscale_factor * 128), name='reshape')(conv_features)\n",
    "y = Bidirectional(CuDNNLSTM(units=512, return_sequences=True),\n",
    "                  name='biLSTM_1')(y)\n",
    "y = Bidirectional(CuDNNLSTM(units=512, return_sequences=True),\n",
    "                  name='biLSTM_2')(y)\n",
    "output_layer = TimeDistributed(Dense(\n",
    "    units=vocab_size+1, kernel_initializer='he_normal', activation='softmax'), name='char_output')(y)\n",
    "\n",
    "labels = Input(shape=(max_string_len, ))\n",
    "label_length = Input(shape=(1,))\n",
    "input_length = Input(shape=(1,))\n",
    "loss_layer = Lambda(ctc_loss, output_shape=(1,), name='loss_layer')(\n",
    "    [output_layer, labels, input_length, label_length])\n",
    "input_tensors = [base_model.input, labels, label_length, input_length]\n",
    "train_model = Model(inputs=input_tensors, outputs=loss_layer)\n",
    "print('=> Build completed successfully <=')\n",
    "print(f'=> Creating model replicas for distributed training across {ngpus} gpus <=')\n",
    "\n",
    "pmodel = multi_gpu_model(train_model, ngpus)\n",
    "pmodel.load_weights('weights_backup/top_weights.h5')\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "sess = get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 test images\n"
     ]
    }
   ],
   "source": [
    "test_images = list(iglob('../dataset/val/*'))\n",
    "test_images.sort()\n",
    "print(f'Found {len(test_images)} test images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(x):\n",
    "    h, w, _ = np.array(load_img(x)).shape\n",
    "    new_h = 64\n",
    "    new_w = int(np.round((64/h) * w, 0))\n",
    "    img = img_to_array(load_img(x, color_mode='grayscale', target_size=(new_h, new_w)))[:,:,0]/255.\n",
    "    blank_img = np.zeros((64, max_w))\n",
    "    blank_img[:img.shape[0], :img.shape[1]] = img\n",
    "    blank_img = blank_img.T\n",
    "    blank_img = np.expand_dims(blank_img, axis=-1)\n",
    "    blank_img = np.expand_dims(blank_img, axis=0)\n",
    "    return blank_img, img\n",
    "labels = [x.split('/')[-1].split('_')[0] for x in test_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906bf61d5de746cba6738e618acb41b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = []\n",
    "for idx,i in tqdm_notebook(enumerate(test_images)):\n",
    "    inp_img, img = prepare_input(i)\n",
    "    ctc_matrix = model.predict(inp_img)\n",
    "    input_len = np.expand_dims((img.shape[1]//4) - 2, 0)\n",
    "    preds = model.predict(inp_img)\n",
    "    out = np.argmax(preds[0][2:input_len[0]], axis=-1)\n",
    "    decoded_labels = ''.join([idx_letter[i] for i,x in groupby(out)])\n",
    "#     preds = sess.run(ctc_decode(ctc_matrix[:,2:,:], input_len, greedy=True, beam_width=100, top_paths=1))\n",
    "#     decoded_labels = ''.join([idx_letter[i] for i,x in groupby(preds[0][0][0])])\n",
    "    p.append(decoded_labels)\n",
    "    plt.figure()   \n",
    "    plt.axis('off')\n",
    "    plt.title(f'Predicted: {decoded_labels}\\nActual: {labels[idx]}', wrap=True, loc='left')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.savefig(f'outputs/{idx}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (exact match ) : 0.43\n",
      "Average editdistance    : 3.815\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "distances = []\n",
    "for i in range(len(p)):\n",
    "    if p[i] == labels[i]:\n",
    "        x+=1\n",
    "    distances.append(editdistance.distance(p[i], labels[i]))\n",
    "print(f'Accuracy (exact match ) : {x/len(p)}')\n",
    "print(f'Average editdistance    : {sum(distances)/len(p)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
